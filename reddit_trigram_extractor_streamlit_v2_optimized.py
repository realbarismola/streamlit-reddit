# -*- coding: utf-8 -*-
"""Reddit-Trigram-Extractor_Streamlit_V2_Optimized.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1s9BMy6F5tmjwe8tb7obw-_vhcKbe2Yoj
"""

import subprocess

# Install the necessary packages
subprocess.call(['pip', 'install', 'praw'])
subprocess.call(['pip', 'install', 'nltk'])
subprocess.call(['pip', 'install', 'gensim'])
subprocess.call(['pip', 'install', 'streamlit'])

import time
import praw
import nltk
import gensim
from nltk.corpus import stopwords
from collections import Counter
from itertools import tee, islice

import nltk
nltk.download('punkt')
nltk.download('stopwords')
import streamlit as st

st.title('Reddit Topic Finder')

def main():
    start_time = time.time()
    # Set up the Reddit API connection
    reddit = praw.Reddit(client_id='nrGPL_tS8GZIp8ccFFDodw',
                         client_secret='j8KG735o7cN_h-DPdNdePekW7FL5tg',
                         user_agent='OldSchoolHaze68')

    # Prompt the user to enter the name of the subreddit to analyze
    subreddit_name = st.text_input('Enter the name of the subreddit to analyze')

    # Wait for the user to enter a subreddit name before proceeding
    if not subreddit_name:
        return

    # Show a message that the tool is processing the query
    with st.spinner('Processing the query. Please wait...'):
        try:
            # Get the top posts from the subreddit
            subreddit = reddit.subreddit(subreddit_name)
            all_posts = subreddit.top(limit=None)

            # Extract trigrams from the posts
            trigrams = []
            for post in all_posts:
                # Combine the title and body of the post
                text = post.title + ' ' + post.selftext
                # Tokenize the text into words
                words = nltk.word_tokenize(text.lower())
                # Remove stop words and punctuation marks
                stop_words = set(stopwords.words('english'))
                words = [word for word in words if word.isalpha() and word not in stop_words]
                # Extract trigrams from the text
                trigrams.extend(zip(words, islice(words, 1, None), islice(words, 2, None)))

            # Create a dictionary for the trigrams and their frequency
            trigram_dict = Counter()
            for trigram in trigrams:
                trigram_dict[trigram] += 1

            # Remove trigrams that contain stop words
            for trigram in list(trigram_dict):
                if any(word in stop_words for word in trigram):
                    del trigram_dict[trigram]

            # Print the top 10 most common trigrams
            st.write('Top 10 most common trigrams:')
            for trigram, count in trigram_dict.most_common(10):
                st.write(f'{trigram} ({count} occurrences)')

        except Exception as e:
            st.write(f'Error: {e}')

    # Measure the elapsed time and display it to the user
    elapsed_time = time.time() - start_time
    st.write(f'Time elapsed: {elapsed_time:.2f} seconds')
    
if __name__ == '__main__':
    main()
